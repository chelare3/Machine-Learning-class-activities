---
title: "QTM 6300: Assignment 4"
author: "(Insert Name)"
date: "OCtober 2024"
format: html
editor: source
self-contained: true
toc: true
toc-expand: true
toc-depth: 3
---


```{r setup, include=FALSE}
#knitr::opts_knit$set(root.dir = '/Users/diana/Babson MSBA/Machine learning')
```

# Context

Let’s take a look at the data located in ebayAuctions.csv. Each row represents an auction, with the columns specifying various auction characteristics, including information about the seller (SellerRating) and the item (Category). Our goal here is to predict whether the auction will turn out to be competitive (Competitive), here defined as receiving 2 or more bids. This type of prediction is crucial for any type of automated trading algorithm, as we would like to find auctions with relatively little competition in the hopes of getting a better final price.


# Import Data and Data Management

1. We’ll be trying predict competitiveness (use the Competitive variable as the target) using a logistic regression model. To get ready for modeling, complete the following data management steps:

* Since we’re thinking about making our predictions of competitiveness at the beginning of the auction, we can really in good faith use ClosePrice; remove it from the data frame.

* Convert the target to a logical.

* Convert other variables to factors as necessary.

* Partition the data using a 60-40 training-test split using random seed 1234.


```{r}
df <- read.csv("eBayAuctions.csv")
# View(df)
df$ClosePrice <- NULL
df$Competitive <- as.logical(df$Competitive)
df$Currency <- as.factor(df$Currency)
df$Category <- as.factor(df$Category)
df$EndDay <- as.factor(df$EndDay)


set.seed(1234) # R Version 2024.04.2+764 

```

# Partition

2. Please set up training partition as 60% of the data, and test data as the rest.

```{r}
N <- nrow(df)
trainingSize <- round(N*0.6)
trainingCases <- sample(N, trainingSize)

training  <- df[trainingCases,]
test <- df[-trainingCases,]
```


# Build Model

3. Construct a logistic regression model for Competitive as a function of all other available variables. Afterwards, create a new model by conducting backward stepwise variable elimination. We'll be using this smaller and more efficient model for the remainder of the questions here. 


```{r}
model1 <- glm(Competitive ~ ., data=training, family=binomial)
options(scipen = 100)
summary(model1)
```



# Interpret

4. Try to interpret the coefficient for Duration.

Answer: the coefficient for duration is -0.09, when a coefficient is negative it means the odds we are measuring decrease. this means that for every extra day the show last the odds of the auction being competitive decrease. 

5. Try to interpret the coefficient for CurrencyGBP. Note that this variable is a dummy for Currency being British Pounds.

Answer: the coefficient for currencyGBP is 1.44 it is positive so the relationship is positive, this means that acutions that are in this currency are more likely to be competitive, it has 2 stars * so it is relatively significant 

# this is a personal note* a dummy variable present categorical values in 1 or 0, in this case, the currency is british pounds or is something else, if it is british pounds then its 1, if it is any other currency then it will be 0. also this coefficient is positive so this means that the relationship is positive and this means that auctions in GBP are more likely to be competitive. it is relevant it has 2 stars, it is higher compared to euro that is the one we dont have in the model. 


# Evaluating Model

6. Using a cut-off probability of 0.5, what is the error rate associated with your model? Use R to calculate it. 

Answer:


```{r}
test$predictions <- predict(model1, test, type="response")
predictions <- test$predictions
#store TRUE/Falses
test$predictionsTF <- (test$predictions >= 0.5)
predictionsTF <- test$predictionsTF
observations <-test$Competitive

table(predictionsTF, test$Competitive)
error_rate <- sum(predictionsTF != observations)/nrow(test)
error_rate
```


## Error Rate

7. Show the confusion matrix. Then, calculate the error rate manually by using R as a calculator using the numbers shown in the confusion matrix. Make sure this is the same as your previous error rate calculation in R!

```{r}
# error rate= 113 + 174/ 202 + 113 +174 + 300 = 0,3637
```

## Benchmark Error Rate

8. What is the Benchmark Error Rate? Does this show to be a useful model?

Answer: 47,66%

```{r}
source("BabsonAnalytics.R")
error_bench <- benchmarkErrorRate(training$Competitive, test$Competitive)
error_bench
```


# Sensitivity and Specificity

9. Calculate the sensitivity and specificity for the default cutoff probability (which is 0.5).

Answer: sensitivity is 72,64% and specify is 53,72%

```{r}
sensitivity <- sum(predictionsTF == TRUE & observations == TRUE)/sum(observations == TRUE)
sensitivity

specificity <- sum(predictionsTF == FALSE & observations == FALSE)/sum(observations == FALSE)
specificity
```


# ROC Chart

10. Imagine we now increase the cut-off probability from 0.5 to 0.6. Does the specificity increase or decrease? How do you know?

Answer: when you increase the probaability, the specificity will increase, raising the cut-off makes the model better at saying “not competitive”


11. Using the ROC Chart, does it show that the model is more or less useful than the benchmark? How do you know?
 It is more useful because it is above the benchmark 
```{r}
ROCChart(observations, predictions)
```




