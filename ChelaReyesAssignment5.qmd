---
title: "Assignment 5: kNN Regression and Classification"
author: "Eric W. Chan"
date: "October 8, 2024"
format: html
editor: source
self-contained: true
toc: true
toc-expand: true
toc-depth: 3
---


```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = '/Users/diana/Babson MSBA/Machine learning')
rm(list = ls()) # clears global environment
#knitr::opts_knit$set(root.dir = '/Users/diana/Babson MSBA/Machine learning')
```

# Context

Letâ€™s take a look at the data located in UniversalBank.csv. Each row represents a customer at small but rapidly growing bank. The columns measure all sorts of customer characteristics, ranging from their demographic information (e.g., Age, Family) to whether they currently have various accounts open with the bank (e.g., Securities Account, CD Account). For a complete description of the fields, consult the data page on Canvas.

There are two characteristics of customers that would be used for the company to predict.

Task 1. First, the bank would like to predict a customer's Mortgage amount (the "Mortgage" variable.) The bank would like a model to make an educated prediction on income so that they may target customers with appropriate marketing.

Task 2. Secondly, the bank is aggressively trying to convert customers from depositors into borrowers through its personal loan program. The column **Personal Loan** shows whether each customer responded to a direct marketing campaign related to this program. The marketing team is now trying to understand what types of customers responds to new personal loans marketing. If they can establish reasonably strong predictive power, they will deploy the model more widely across their customer base to identify promising leads and a more nuanced target market.


# Task 1: Predicting Mortgage Amount

## Question 1

Do the following:

* Import the data as "bank"

* Remove all non-numeric variables from the data frame. Anything that feels more categorical than numeric should be nulled out. This is because in kNN, we cannot use any variable as predictors when we have difficulty calculating the distance. I would also say that anything that doesn't make sense as a numeric value (like Zip Code), or something that should not be predictive (like ID) of the dependent variable, should also be nulled out.


```{r}
bank <- read.csv('UniversalBank.csv')
#View(bank)

bank$ID <- NULL
bank$ZIP.Code  <- NULL
bank$Family  <- NULL
bank$Education  <- NULL
bank$Personal.Loan  <- NULL
bank$Securities.Account  <- NULL
bank$CD.Account  <- NULL
bank$Online  <- NULL
bank$CreditCard  <- NULL
```


## Question 2

* Set a seed of 72 and partition a training set with 55% of the data.

```{r}
set.seed(72) # R Version 2024.04.2+764 
N <- nrow(bank)
trainingSize <- round(N*0.55)
trainingCases <- sample(N, trainingSize)
#View(trainingCases)
training <- bank[trainingCases, ]
#View(TainingCases)
test <- bank[-trainingCases, ]
```


## Question 3

* Build a kNN regression model using standardized features ("indepedent variables") to predict Mortgage in R. Set it up so that you are using the four closest neighbors for the predictions.

```{r}
library(caret)
model <- knnreg(Mortgage ~ ., data=training, k=3, preProcess=c("center","scale"))
```

## Question 4

Apply the model to the test data frame. Then, store the predicted values in both the object "predictions" and within the test data frame so you can clearly see what the predictions are when you view the data frame.

```{r}
predictions <- predict(model, test)
test$predictions <- predict(model, test)
#View(test)
```

## Question 5
Evaluate the model. Calculate the MAPE and the RMSE. What are they? Interpret each of the them.
Answer: R gave us NaN value in the mape because we have many values in the observation that are 0

```{r}
observations <- test$Mortgage
errors <- observations - predictions
mape <- mean(abs(observations-predictions)/observations)
mape
rmse <- sqrt(mean((observations-predictions)^2))
rmse
```

## Question 6
In one sentence, interpret the MAPE from the last question using the appropriate units. (Note: It is possible that you received a MAPE that is NaN or Inf, or basically incalculable. If you do, I will provide extra credit IF you can *clearly* explain why it is incalculable. Try to think about the MAPE equation and also take a look at the data.))

Answer:  R gave us NaN value in the mape because we have many values in the observation that are 0, when we divide by 0 that happens. 

## Question 7
In one sentence, interpret the RMSE from Question 6 using the appropriate units.

Answer: the rmse shows the average difference between the predicted value and the actual one. In this case an rmse of 114.0135 is in USD, and it is telling us that on average the mode prediction for the mortgage amount deviates from the actual values by aprox $114000  

## Question 8
Calculate the benchmark MAPE and RMSE when using the mean as the prediction. Is your model useful? Why or why not?

Answer: with inf values on the benchmark mape we cannot fully determine if the model is useful just from mape, as it makes direct comparison challenging. however with the rmse value we could say that since the one from the model is higher than the benchmark rmse, then the model most likely is not useful.

```{r}
errors_bench <- observations - mean(training$Mortgage)
mape_bench <- mean(abs(errors_bench)/observations)
mape_bench
rmse_bench <- sqrt(mean(errors_bench^2))
rmse_bench

```


# Task 2: Predicting Personal Loan Offer Acceptance

## Question 9

We will now turn our attention to creating a kNN Classification model to predict whether a customer would accept a personal loan offer. Make sure your code is in the following order:

* First, let's clear the global environment to make sure we don't confuse our previous data and model with this one.

* Second, Import the data as "bank" once again.

* Third, remove all non-numeric variables from the data frame except the target variable. Anything that feels more categorical than numeric should be nulled out. This is because in kNN, we cannot use any variable as predictors when we have difficulty calculating the distance. I would also say that anything that doesn't make sense as a numeric value (like Zip Code), or something that should not be predictive (like ID) of the dependent variable, should also be nulled out.

* Fourth, convert the target variable to a factor

* Fifth, standardize all the numeric predictors.

* Sixth, set a seed of 72 and partition a training set with 55% of the data once again.

```{r}
rm(list = ls()) # clears global environment
#knitr::opts_knit$set(root.dir = '/Users/diana/Babson MSBA/Machine learning')
bank <- read.csv('UniversalBank.csv')
#View(bank)
bank$ID <- NULL
bank$ZIP.Code  <- NULL
bank$Family  <- NULL
bank$Education  <- NULL
bank$Securities.Account  <- NULL
bank$CD.Account  <- NULL
bank$Online  <- NULL
bank$CreditCard  <- NULL

bank$Personal.Loan <- as.factor(bank$Personal.Loan)
library(caret)
standardizer <- preProcess(bank, c("center","scale"))
bank <- predict(standardizer, bank)

set.seed(72) # R Version 2024.04.2+764 
N <- nrow(bank)
trainingSize <- round(N*0.55)
trainingCases <- sample(N, trainingSize)
train <- bank[trainingCases, ]
test <- bank[-trainingCases, ]
```

## Question 10

* Train the kNN classification model using all available numeric inputs, using the four closest neighbors to make a prediction. Make sure to standardize your predictors.

```{r}
model <- knn3(Personal.Loan ~ ., data=train, k=4)
predictions <- predict(model, test, type="class")
test$predictions <- predict(model, test, type="class")
#View(test)
```


## Question 11

Create the confusion matrix to see the errors. 

```{r}
observations <- test$Personal.Loan


table(predictions, observations)

```

## Question 12

How many total predictions did the model get correct? (Not percentage)

Answer: 2018

```{r}
sum(1946,72)
```


## Question 13

How many total predictions did the model get incorrect? (Not percentage)

Answer: 232

```{r}
sum(92+140)
```


## Question 14

Manually calculate the error rate (according to numbers you received in the confusion matrix. Show calculations using R as a calculator.

Answer: 10.31%

```{r}
sum(92,140)/sum(1946,140,92,72)
```



## Question 15

Now, Calculate the error rate using R code. Make sure your manual calculation is correct.

```{r}
error_rate <- sum(predictions != observations)/nrow(test)
error_rate
```


## Question 16

Calculate the benchmark error rate. You can do this using code. (NOte that, however- for practice- you should also be able to get the same benchmark error rate using the confusion matrix!)

Answer: 9,42%

```{r}
source('BabsonAnalytics.R')
error_bench <- benchmarkErrorRate(train$Personal.Loan, test$Personal.Loan)
error_bench
```


## Question 17

Is your error rate for the model better than the benchmark?

Answer: since the model error rate is higher than the benchmark, it is not better than the benchmark, this is indicating that the model does not outperform the simple benchmark approach in terms of accurancy 




## Question 18

Calculate the sensitivity. You can use either code or the confusion matrix to do so manually.

Answer: 33,9% 


```{r}
sensitivity <- sum(predictions == 1 & observations == 1)/sum(observations == 1)
sensitivity

72/(72+140)*100
```


## Question 19

Calculate the specificity. You can use either code or the confusion matrix to do so manually.

Answer: 95,4%

```{r}
specificity <- sum(predictions == 0 & observations == 0)/sum(observations == 0)
specificity

1946/(1946+92)*100
```

